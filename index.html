<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Sam Nguyen</title>

    <meta name="author" content="Sam Nguyen">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css?v=20260129">
    <script type="application/ld+json">
    {
      "@context": "https://schema.org/",
      "@type": "Person",
      "name": "Sam Nguyen",
      "url": "https://primepake.github.io/",
      "affiliation": [
        {
          "@type": "Organization",
          "name": "Pipio AI",
          "url": "https://pipio.ai"
        },
        {
          "@type": "Organization",
          "name": "Captions AI",
          "url": "https://captions.ai"
        }
      ],
      "sameAs": [
        "https://www.linkedin.com/in/primepake/",
        "https://github.com/primepake"
      ],
      "jobTitle": "Senior Research Engineer",
      "description": "AI/ML Researcher with 8+ years of experience in generative AI, virtual presenters, and video/audio synthesis."
    }
    </script>
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Sam Nguyen
                </p>
                <p style="text-align:center">
                  <a class="social-link" href="https://github.com/primepake">
                    <img src="https://cdn.simpleicons.org/github/1772d0" alt="GitHub" width="18" height="18">
                    <span>Github</span>
                  </a>
                  <span class="social-separator">¬∑</span>
                  <a class="social-link" href="https://www.linkedin.com/in/primepake/">
                    <img src="https://www.svgrepo.com/show/157006/linkedin.svg" alt="LinkedIn" width="18" height="18">
                    <span>LinkedIn</span>
                  </a>
                </p>
                <p style="text-align:center; margin-top:6px; margin-bottom:16px;">
                  <a class="contact-button" href="mailto:nguyennhutsam.math@gmail.com">Contact Me</a>
                </p>
                <p class="bio-pills" style="text-align:center;">
                  <span class="bio-pill">Machine Learning</span>
                  <span class="bio-pill">Deep Learning</span>
                  <span class="bio-pill">Computer Vision</span>
                  <span class="bio-pill">Flow Matching</span>
                  <span class="bio-pill">Diffusion</span>
                </p>
                <p>
                  I'm a <strong>Senior Research Engineer at <a href="https://pipio.ai/">Pipio AI</a></strong>, working on multi-modal video synthesis, visual dialog editing, and audio-driven video editing.
                  <br>
                  <br>
                  Previously, I was at <strong><a href="https://captions.ai/">Captions AI</a></strong> where I'm core person developed of Lipdub (video dubbing engine) and contributed to Mirage. I also co-founded <strong><a href="https://dizim.ai/">dizim</a></strong>, a virtual presenter platform recognized as Top 10 at Techfest 2022.
                </p>
                <p class="bio-location" style="text-align:center; margin-top:8px;">
                  üìç Ho Chi Minh City, Vietnam
                </p>
              </td>
              <td style="padding:2.5%;width:37%;max-width:37%">
                <div class="profile-photo-frame">
                  <img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/portrait.jpg" class="profile-photo">
                </div>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2>Projects</h2>
                <p>
                  I'm passionate about generative AI, particularly video/audio synthesis, flow matching, and diffusion models. With 7+ years of experience, I've built production systems for lip-sync, text-to-speech, and virtual presenters serving hundreds of thousands of users.
                  <br><br>
                  My open-source work focuses on flow matching implementations and audio/video generation techniques. I enjoy exploring efficient training methods and novel architectures.
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px 10px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

<tr class="paper-row highlight-row">
  <td style="padding:16px;width:20%;vertical-align:middle">
    <div class="one">
      <img src='images/edityourself_teaser.png' width=100% style="border-radius: 8px;">
    </div>
  </td>
  <td style="padding:8px;width:80%;vertical-align:middle">
    <a class="paper-title-link" href="https://edit-yourself.github.io">
      <span class="papertitle">EditYourself: Audio-Driven Generation and Manipulation of Talking Head Videos</span>
      <span class="new-badge">NEW</span>
    </a>
    <br>
    John Flynn,
    Wolfgang Paier,
    Dimitar Dinev,
    <strong>Sam Nhut Nguyen</strong>,
    Hayk Poghosyan,
    Manuel Toribio,
    Sandipan Banerjee,
    Guy Gafni
    <br>
    <span class="venue-tag">ArXiv</span> 2026
    <br>
    <a href="https://edit-yourself.github.io">project page</a>
    <span class="paper-separator">¬∑</span>
    <a href="https://arxiv.org/abs/2601.22127">arXiv</a>
    <p></p>
    <p>
    EditYourself is a diffusion-based video editing model for talking heads, enabling transcript-driven lip-syncing, insertion, removal and retiming of speech while preserving identity and visual fidelity.
    </p>
  </td>
</tr>

<tr class="paper-row">
  <td style="padding:16px;width:20%;vertical-align:middle">
    <div class="one">
      <img src='https://opengraph.githubassets.com/1/primepake/wav2lip_288x288' width=100% style="border-radius: 8px;">
    </div>
  </td>
  <td style="padding:8px;width:80%;vertical-align:middle">
    <a class="paper-title-link" href="https://github.com/primepake/wav2lip_288x288">
      <span class="papertitle">Wav2Lip 288x288</span>
    </a>
    <br>
    <strong>Sam Nguyen</strong>
    <br>
    <span class="venue-tag">Open Source</span>
    <br>
    <a href="https://github.com/primepake/wav2lip_288x288">GitHub</a>
    <br>
    <a href="https://github.com/primepake/wav2lip_288x288" style="text-decoration: none;">
      <img src="https://img.shields.io/github/stars/primepake/wav2lip_288x288?style=social" alt="GitHub stars" style="vertical-align: middle; margin-right: 5px;">
      <img src="https://img.shields.io/github/forks/primepake/wav2lip_288x288?style=social" alt="GitHub forks" style="vertical-align: middle;">
    </a>
    <p></p>
    <p>
    High-resolution Wav2Lip implementation at 288x288 with complete training pipeline. Enables high-fidelity lip-synchronization for video dubbing applications.
    </p>
  </td>
</tr>

<tr class="paper-row">
  <td style="padding:16px;width:20%;vertical-align:middle">
    <div class="one">
      <img src='https://opengraph.githubassets.com/1/primepake/splitmeanflow' width=100% style="border-radius: 8px;">
    </div>
  </td>
  <td style="padding:8px;width:80%;vertical-align:middle">
    <a href="https://github.com/primepake/splitmeanflow">
      <span class="papertitle">Split Mean Flow</span>
    </a>
    <br>
    <strong>Sam Nguyen</strong>
    <br>
    <span class="venue-tag">Open Source</span>
    <br>
    <a href="https://github.com/primepake/splitmeanflow">GitHub</a>
    <br>
    <a href="https://github.com/primepake/splitmeanflow" style="text-decoration: none;">
      <img src="https://img.shields.io/github/stars/primepake/splitmeanflow?style=social" alt="GitHub stars" style="vertical-align: middle; margin-right: 5px;">
      <img src="https://img.shields.io/github/forks/primepake/splitmeanflow?style=social" alt="GitHub forks" style="vertical-align: middle;">
    </a>
    <p></p>
    <p>
    Unofficial implementation of Split Mean Flow from ByteDance. One-step generative modeling using flow matching techniques for efficient sampling.
    </p>
  </td>
</tr>

<tr class="paper-row">
  <td style="padding:16px;width:20%;vertical-align:middle">
    <div class="one">
      <img src='https://opengraph.githubassets.com/1/primepake/learnable-speech' width=100% style="border-radius: 8px;">
    </div>
  </td>
  <td style="padding:8px;width:80%;vertical-align:middle">
    <a href="https://github.com/primepake/learnable-speech">
      <span class="papertitle">Learnable Speech</span>
    </a>
    <br>
    <strong>Sam Nguyen</strong>
    <br>
    <span class="venue-tag">Open Source</span>
    <br>
    <a href="https://github.com/primepake/learnable-speech">GitHub</a>
    <br>
    <a href="https://github.com/primepake/learnable-speech" style="text-decoration: none;">
      <img src="https://img.shields.io/github/stars/primepake/learnable-speech?style=social" alt="GitHub stars" style="vertical-align: middle; margin-right: 5px;">
      <img src="https://img.shields.io/github/forks/primepake/learnable-speech?style=social" alt="GitHub forks" style="vertical-align: middle;">
    </a>
    <p></p>
    <p>
    Text-to-speech with learnable audio encoder without alignment with transcript reference. Novel approach to speech synthesis using learned representations.
    </p>
  </td>
</tr>

<tr class="paper-row">
  <td style="padding:16px;width:20%;vertical-align:middle">
    <div class="one">
      <img src='https://opengraph.githubassets.com/1/primepake/dac_vae' width=100% style="border-radius: 8px;">
    </div>
  </td>
  <td style="padding:8px;width:80%;vertical-align:middle">
    <a href="https://github.com/primepake/dac_vae">
      <span class="papertitle">DAC-VAE: Descript Audio Codec VAE</span>
    </a>
    <br>
    <strong>Sam Nguyen</strong>
    <br>
    <span class="venue-tag">Open Source</span>
    <br>
    <a href="https://github.com/primepake/dac_vae">GitHub</a>
    <br>
    <a href="https://github.com/primepake/dac_vae" style="text-decoration: none;">
      <img src="https://img.shields.io/github/stars/primepake/dac_vae?style=social" alt="GitHub stars" style="vertical-align: middle; margin-right: 5px;">
      <img src="https://img.shields.io/github/forks/primepake/dac_vae?style=social" alt="GitHub forks" style="vertical-align: middle;">
    </a>
    <p></p>
    <p>
    Variational Autoencoder variant of Descript Audio Codec (.dac-vae) for high-fidelity audio compression. Enables efficient audio encoding for generative models.
    </p>
  </td>
</tr>

          </tbody></table>

          
					<table style="width:100%; margin:0 auto; border:0; border-spacing:0; padding:16px;"><tbody>
            <tr>
              <td>
                <h2>Experience</h2>
              </td>
            </tr>
          </tbody></table>
          <table class="misc-table"><tbody>
            <tr class="misc-row">
              <td class="misc-label">üíº Work</td>
              <td class="misc-content">
                <ul>
                  <li><strong><a href="https://pipio.ai/">Pipio AI</a></strong> - Senior Research Engineer (2025-Present): Multi-modal video synthesis, visual dialog editing, lip-synchronization</li>
                  <li><strong><a href="https://captions.ai/">Captions AI</a></strong> - Senior Member of Technical Staff (2022-2025): Lipdub development, contributed to Mirage</li>
                  <li><strong><a href="https://dizim.ai/">dizim</a></strong> - Head of AI / Co-Founder (2021-2022): Top 10 Techfest 2022, virtual presenter platform serving 200k+ users</li>
                  <li><strong>VTC Academy</strong> - Lead Machine Learning (2022-2023): Led 8-person team for AI-powered educational platform</li>
                  <li><strong><a href="https://ausynclab.io/">Ausynclab</a></strong> - Technical Advisor: Advised on voice cloning technology achieving best local Vietnamese voice quality, reached 100k+ users within months of launch</li>
                </ul>
              </td>
            </tr>
            <tr class="misc-row">
              <td class="misc-label">üéì Education</td>
              <td class="misc-content">
                <ul>
                  <li><strong>BSc in Mathematics and Computer Science</strong> - VNU-HCMUS University of Science (2015-2019)</li>
                  <li><strong>Thesis:</strong> "Talking Face via Audio Driven" - Score: 9.8/10</li>
                </ul>
              </td>
            </tr>
            <tr class="misc-row">
              <td class="misc-label">üèÜ Honors</td>
              <td class="misc-content">
                <ul>
                  <li>Semi-Final Techfest 2021 - Top 20 Startups</li>
                  <li>Silver Winner - SAP SME SEEDx Development Challenge 2020</li>
                </ul>
              </td>
            </tr>
            <tr class="misc-row">
              <td class="misc-label">üõ†Ô∏è Skills</td>
              <td class="misc-content">
                Large Scale Training, GANs, VAEs, Flow Matching, Diffusion, LLM, Kubernetes, Azure, PyTorch
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p class="site-credit">
                  Website template from <a href="https://github.com/jonbarron/jonbarron_website">Jon Barron</a>.
                </p>
                <p class="legal-links">
                  <span class="legal-copy">¬© 2026 Sam Nguyen ¬∑ All rights reserved</span>
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
